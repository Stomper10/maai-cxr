{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d58ef305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm as tq\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import BatchSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as ddp\n",
    "from torchinfo import summary\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import (\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    "    RichProgressBar,\n",
    "    RichModelSummary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ca91f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    def __init__(self):\n",
    "        return\n",
    "configs = CFG()\n",
    "configs.dataset_dir = '/mnt/e/dataset/chexpert/CheXpert-v1.0'\n",
    "configs.batch_size = 4\n",
    "configs.image_size = (1024, 1024)\n",
    "configs.image_add_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "27b46335",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset): # batch dataset\n",
    "    def __init__(self, configs, mode='train'):\n",
    "        # arguments\n",
    "        self.configs = configs\n",
    "        self.image_size = configs.image_size\n",
    "        self.image_add_size = configs.image_add_size\n",
    "        self.mode = mode\n",
    "        self.data_dir = f\"{configs.dataset_dir}/{mode}.csv\"\n",
    "        \n",
    "        # configuration\n",
    "        self.batch_size = configs.batch_size\n",
    "        self.image_size = configs.image_size\n",
    "        \n",
    "        # data processing    \n",
    "        data = pd.read_csv(self.data_dir).fillna(0.0)\n",
    "        data['Path'] = data['Path'].str.replace(\"CheXpert-v1.0\", configs.dataset_dir)\n",
    "        for col_idx in range(5, len(data.columns)):\n",
    "            data[data.columns[col_idx]] = data[data.columns[col_idx]].astype(str)\n",
    "            data[data.columns[col_idx]] = data[data.columns[col_idx]].str.replace(\"-1\", \"0\").astype(float)\n",
    "            # data[data.columns[col_idx]] = data[data.columns[col_idx]].astype(int)\n",
    "        \n",
    "        # store data\n",
    "        self.X = data['Path'].values\n",
    "        self.Y = data.values[:, 5:]\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = (\n",
    "            self.train_transform(self.resize(cv2.imread(self.X[idx])))\n",
    "            if (self.mode == 'train')\n",
    "            else self.resize(cv2.imread(self.X[idx]))\n",
    "            )\n",
    "        \n",
    "        y = (self.Y[idx] \n",
    "             if (self.mode in ['train', 'valid', 'val'] )\n",
    "             else None\n",
    "            )\n",
    "        return x, y\n",
    "    \n",
    "    def resize(self, x):\n",
    "        H, W, C = x.shape\n",
    "        \n",
    "        if H>W:\n",
    "            resize_fn = A.Resize(\n",
    "                height=self.image_size[0]*H//W + self.image_add_size, \n",
    "                width=self.image_size[1] + self.image_add_size\n",
    "            )\n",
    "        else: # W < H\n",
    "            resize_fn = A.Resize(\n",
    "                height=self.image_size[0] + self.image_add_size, \n",
    "                width=self.image_size[1]*W//H + self.image_add_size\n",
    "            )\n",
    "        \n",
    "        x = A.Compose([\n",
    "            resize_fn,\n",
    "            A.CenterCrop(height=self.image_size[0], width=self.image_size[1]),            \n",
    "        ])(image=x)['image']\n",
    "        \n",
    "        return x     # dtype : numpy array    \n",
    "    \n",
    "    def train_transform(self, x):\n",
    "        x = A.Compose([\n",
    "            A.Affine(\n",
    "                scale = 0.95,\n",
    "                translate_percent=0.05, # moving\n",
    "                shear = 0.05,           # distortion      \n",
    "                rotate=None,\n",
    "                interpolation=1,\n",
    "            ),\n",
    "            ToTensorV2()\n",
    "        ])(image=x)['image']\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff1ecf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11037fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d1efe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5086ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl",
   "language": "python",
   "name": "pl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
